# Multilayer_Perceptron

Question: 
Implement an articial neural network (ANN) by stacking up your perceptron. The architecture of the ANN is up to you. Use sigmoid function for activation function and backpropagation to train your ANN. Use the same MNIST data for training and testing. Print out accuracy,
precision and recall at the end.


The accuracy was 95.26%

Confusion Matrix is 
 [[57620      0   	614    	  98     94   	674   	476   	150   	388     548]
 [    0	  66868      50    	  46     18      50   	172   	386   	304   	252]
 [   72   	178 	57972      818   	312   	160   	194 	 1246   	556    	 48]
 [   76   	226   	568    56334     26 	 1470    	 66   	420   	970   	712]
 [  106    	 34   	378     	 2 	55912   	298   	278   	252   	356 	 1272]
 [  216   	120   	188 	  1442     42 	49008   	722    	 34   	740   	284]
 [  226   	218   	622   	 206   	492   	648 	55186      38   	544    	 54]
 [  110   	126   	580   	 622   	112   	144    	 96 	57956   	494   	652]
 [  108   	330   	692   	 692   	152   	790   	276   	160 	53762   	566]
 [  266       0   	256   	 340 	 1760   	278    	 14 	 1038   	326 	56152]]

Precision is:  0.9448287919839756

Recall is: 0.9446166666666667
